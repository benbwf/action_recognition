{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Notebook to predict actions in video, and to score the accuracy of the model using a IOU-like method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ops.dataset import TSNDataSet\n",
    "from ops import dataset_config\n",
    "from ops.models import TSN\n",
    "from ops.transforms import *\n",
    "from tools.vid2img import vid2jpg, convert_folder\n",
    "from env_vars import VIDEOS_DIR, PREPROCESSED_DATA_ROOT, RAW_DATA_ROOT\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "from torch.nn import functional as F #for softmax "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    res = []\n",
    "    for k in topk:\n",
    "         correct_k = correct[:k].contiguous().view(-1).float().sum(0)\n",
    "         res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "def parse_shift_option_from_log_name(log_name):\n",
    "    if 'shift' in log_name:\n",
    "        strings = log_name.split('_')\n",
    "        for i, s in enumerate(strings):\n",
    "            if 'shift' in s:\n",
    "                break\n",
    "        return True, int(strings[i].replace('shift', '')), strings[i + 1]\n",
    "    else:\n",
    "        return False, None, None\n",
    "    \n",
    "\n",
    "def eval_video(video_data, net, this_test_segments, modality):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        i, data, label = video_data\n",
    "        batch_size = label.numel()\n",
    "        num_crop = test_crops\n",
    "        if dense_sample:\n",
    "            num_crop *= 10  # 10 clips for testing when using dense sample\n",
    "\n",
    "        if twice_sample:\n",
    "            num_crop *= 2\n",
    "\n",
    "        if modality == 'RGB':\n",
    "            length = 3\n",
    "        elif modality == 'Flow':\n",
    "            length = 10\n",
    "        elif modality == 'RGBDiff':\n",
    "            length = 18\n",
    "        else:\n",
    "            raise ValueError(\"Unknown modality \"+ modality)\n",
    "\n",
    "        data_in = data.view(-1, length, data.size(2), data.size(3))\n",
    "        if is_shift:\n",
    "            data_in = data_in.view(batch_size * num_crop, this_test_segments, length, data_in.size(2), data_in.size(3))\n",
    "        rst = net(data_in)\n",
    "        rst = rst.reshape(batch_size, num_crop, -1).mean(1)\n",
    "\n",
    "        if softmax:\n",
    "            # take the softmax to normalize the output to probability\n",
    "            rst = F.softmax(rst, dim=1)\n",
    "\n",
    "        rst = rst.data.cpu().numpy().copy()\n",
    "\n",
    "        if net.module.is_shift:\n",
    "            rst = rst.reshape(batch_size, num_class)\n",
    "        else:\n",
    "            rst = rst.reshape((batch_size, -1, num_class)).mean(axis=1).reshape((batch_size, num_class))\n",
    "\n",
    "        return i, rst, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change these parameters as needed\n",
    "Set your dataset_version, weights path (this_weights), source directory, and output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_version = 'pc_101'\n",
    "\n",
    "# set to the path to your model file\n",
    "this_weights = f'checkpoint/'\\\n",
    "               f'20210710_TSM_ite_RGB_resnet50_shift8_blockres_avg_segment8_e150_{dataset_version}_dense/'\\\n",
    "                'checkpoint/ckpt.best.pth.tar'\n",
    "\n",
    "#duration of clip to send to model for prediction\n",
    "#this should represent the rough average length of your actions in the dataset.\n",
    "# example: if your actions are an average of 3 seconds long, then set CLIP_DURATION = 3\n",
    "CLIP_DURATION = 2 #seconds\n",
    "\n",
    "\n",
    "# FOLDERS========================================================================================\n",
    "# video locations for dividing video into clips for getting the predictions\n",
    "\n",
    "source_dir = os.path.join(RAW_DATA_ROOT, 'ite_dataset', 'videos', 'UAT_Stitched_Test_Cases')\n",
    "source_dir = \"C:\\\\Users\\\\User1\\\\Desktop\\\\projects\\\\ITE_APAMS\\\\ite_dataset\\\\videos\\\\210304\\\\A\"\n",
    "video_paths = glob.glob(os.path.join(source_dir, '*.MP4'))\n",
    "\n",
    "\n",
    "# Fixed param, where the ite_dataset is at\n",
    "root_data_path = PREPROCESSED_DATA_ROOT\n",
    "\n",
    "# folder to store the prediction .csv and video files\n",
    "dt = time.strftime('%Y%m%d%H%M', time.localtime())\n",
    "cwd = os.getcwd()\n",
    "output_path = os.path.join(cwd, f'{dt}_{dataset_version}_output') #- used for just dense, full_res = False, test_crops=1\n",
    "\n",
    "Path(output_path).mkdir(exist_ok=True)\n",
    "\n",
    "# temp directory location for storing the split video from source_dir into 2s clips\n",
    "tmp_dir = os.path.join(PREPROCESSED_DATA_ROOT, 'tmp')\n",
    "Path(tmp_dir).mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\User1\\\\Desktop\\\\projects\\\\ITE_APAMS\\\\ite_dataset\\\\videos\\\\210304\\\\A\\\\A_1.MP4',\n",
       " 'C:\\\\Users\\\\User1\\\\Desktop\\\\projects\\\\ITE_APAMS\\\\ite_dataset\\\\videos\\\\210304\\\\A\\\\A_2.MP4',\n",
       " 'C:\\\\Users\\\\User1\\\\Desktop\\\\projects\\\\ITE_APAMS\\\\ite_dataset\\\\videos\\\\210304\\\\A\\\\A_3.MP4']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL PARAMETERS\n",
    "- Inferred by this_weights\n",
    "- Set by User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================================================================================#\n",
    "# Fixed parameters based on the model trained\n",
    "num_segments = 8\n",
    "\n",
    "#============================================================================================================#\n",
    "# Currently tested parameters that can be changed\n",
    "# FOR A MODEL THAT IS TRAINED WITH DENSE_SAMPLE, MUST SET EITHER TO TRUE\n",
    "dense_sample = True  # True \n",
    "twice_sample = False\n",
    "\n",
    "#============================================================================================================#\n",
    "# Parameters that were fixed throughout different models prediction (perhaps could be altered for performance)\n",
    "# Are these training parameters as well?????\n",
    "test_crops = 1  #1\n",
    "full_res = False #False\n",
    "this_test_segments = 8\n",
    "#========================# Data Loading, Etc Parameters (changes based on computer, etc)==========================#\n",
    "batch_size = 2\n",
    "num_workers = 0\n",
    "\n",
    "#============================================================================================================#\n",
    "# Fixed parameters (either from parsing from this_weights, or not really changed)\n",
    "is_shift, shift_div, shift_place = parse_shift_option_from_log_name(this_weights)\n",
    "softmax = True\n",
    "SOFTMAX_THRESH = 0.8\n",
    "\n",
    "#============================================================================================================#\n",
    "# Check for device\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ite: 33 classes\n",
      "\n",
      "    Initializing TSN with base model: resnet50.\n",
      "    TSN Configurations:\n",
      "        input_modality:     RGB\n",
      "        num_segments:       8\n",
      "        new_length:         1\n",
      "        consensus_module:   avg\n",
      "        dropout_ratio:      0.8\n",
      "        img_feature_dim:    256\n",
      "            \n",
      "=> base model: resnet50\n",
      "Adding temporal shift...\n",
      "=> n_segment per stage: [8, 8, 8, 8]\n",
      "=> Processing stage with 3 blocks residual\n",
      "=> Using fold div: 8\n",
      "=> Using fold div: 8\n",
      "=> Using fold div: 8\n",
      "=> Processing stage with 4 blocks residual\n",
      "=> Using fold div: 8\n",
      "=> Using fold div: 8\n",
      "=> Using fold div: 8\n",
      "=> Using fold div: 8\n",
      "=> Processing stage with 6 blocks residual\n",
      "=> Using fold div: 8\n",
      "=> Using fold div: 8\n",
      "=> Using fold div: 8\n",
      "=> Using fold div: 8\n",
      "=> Using fold div: 8\n",
      "=> Using fold div: 8\n",
      "=> Processing stage with 3 blocks residual\n",
      "=> Using fold div: 8\n",
      "=> Using fold div: 8\n",
      "=> Using fold div: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User1\\anaconda3\\envs\\ptcpu\\lib\\site-packages\\torchvision\\transforms\\transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "this_arch = this_weights.split('TSM_')[1].split('_')[2]\n",
    "if 'RGB' in this_weights:\n",
    "        modality = 'RGB'\n",
    "else:\n",
    "    modality = 'Flow'\n",
    "    \n",
    "num_class, train_list, val_list, root_path, prefix = dataset_config.return_dataset(root_data_path, 'ite',\n",
    "                                                                                            modality, version = dataset_version)\n",
    "\n",
    "net = TSN(num_class, this_test_segments if is_shift else 1, modality,\n",
    "              base_model=this_arch,\n",
    "              consensus_type='avg',\n",
    "              img_feature_dim=256,\n",
    "              pretrain='imagenet',\n",
    "              is_shift=is_shift, shift_div=shift_div, shift_place=shift_place,\n",
    "              non_local='_nl' in this_weights,\n",
    "              )\n",
    "\n",
    "if 'tpool' in this_weights:\n",
    "    from ops.temporal_shift import make_temporal_pool\n",
    "    make_temporal_pool(net.base_model, this_test_segments)  # since DataParallel\n",
    "\n",
    "checkpoint = torch.load(this_weights, map_location=torch.device(dev))\n",
    "checkpoint = checkpoint['state_dict']\n",
    "\n",
    "# base_dict = {('base_model.' + k).replace('base_model.fc', 'new_fc'): v for k, v in list(checkpoint.items())}\n",
    "base_dict = {'.'.join(k.split('.')[1:]): v for k, v in list(checkpoint.items())}\n",
    "replace_dict = {'base_model.classifier.weight': 'new_fc.weight',\n",
    "                'base_model.classifier.bias': 'new_fc.bias',\n",
    "                }\n",
    "for k, v in replace_dict.items():\n",
    "    if k in base_dict:\n",
    "        base_dict[v] = base_dict.pop(k)\n",
    "\n",
    "net.load_state_dict(base_dict)\n",
    "\n",
    "input_size = net.scale_size if full_res else net.input_size\n",
    "if test_crops == 1:\n",
    "    cropping = torchvision.transforms.Compose([\n",
    "        GroupScale(net.scale_size),\n",
    "        GroupCenterCrop(input_size),\n",
    "    ])\n",
    "elif test_crops == 3:  # do not flip, so only 5 crops\n",
    "    cropping = torchvision.transforms.Compose([\n",
    "        GroupFullResSample(input_size, net.scale_size, flip=False)\n",
    "    ])\n",
    "elif test_crops == 5:  # do not flip, so only 5 crops\n",
    "    cropping = torchvision.transforms.Compose([\n",
    "        GroupOverSample(input_size, net.scale_size, flip=False)\n",
    "    ])\n",
    "elif test_crops == 10:\n",
    "    cropping = torchvision.transforms.Compose([\n",
    "        GroupOverSample(input_size, net.scale_size)\n",
    "    ])\n",
    "else:\n",
    "    raise ValueError(\"Only 1, 5, 10 crops are supported while we got {}\".format(test_crops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data and create data loaders\n",
    "Just like the training data, our input videos need to be converted to clips and then frames (images) first.\n",
    "We will split the video into clips of equal length (determined by the CLIP_DURATION parameter).\n",
    "These clips will then be converted into frames.\n",
    "Then we will create a dataloader per-video, to be used for prediction later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_video_properties(video_path):\n",
    "    #get video properties\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)      # OpenCV2 version 2 used \"CV_CAP_PROP_FPS\"\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))   # float `width`\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) ) # float `height`\n",
    "    cap.release()\n",
    "    return fps, frame_count, width, height\n",
    "\n",
    "def prepare_video(video_path, preprocess = True, dataloaders = True, del_clips = True):\n",
    "    filename = os.path.basename(video_path)\n",
    "    \n",
    "    #get video properties\n",
    "    fps, frame_count, width, height = get_video_properties(video_path)\n",
    "    \n",
    "    \n",
    "    dest_dir = os.path.join(tmp_dir, filename)\n",
    "    print(dest_dir)\n",
    "    print(f'fps: {fps}, frame count: {frame_count}, clip duration: {CLIP_DURATION}, filename: {filename}')\n",
    "    \n",
    "    if preprocess:\n",
    "        for i in range(0, int(frame_count/fps), int(CLIP_DURATION)):\n",
    "            Path(dest_dir).mkdir(exist_ok=True)\n",
    "            target_filepath = os.path.join(dest_dir, f'{i:04}_{filename}')\n",
    "            \n",
    "            #convert video to clips\n",
    "            ffmpeg_extract_subclip(video_path, i, i + int(CLIP_DURATION), targetname=target_filepath)\n",
    "\n",
    "        #convert clips to images\n",
    "        convert_folder(dest_dir, dest_dir)\n",
    "    \n",
    "    #generate video file list\n",
    "    video_folders_file = 'videofolder.txt'\n",
    "    video_folders_filepath = os.path.join(dest_dir, video_folders_file)\n",
    "    with open(video_folders_filepath, 'w+') as file:\n",
    "        for folder in glob.glob(os.path.join(dest_dir, '*')):\n",
    "            if not os.path.isdir(folder):\n",
    "                continue\n",
    "            num_images = len(glob.glob(os.path.join(folder, '*')))\n",
    "            file.write(f'{folder},{num_images},{-1}\\n')\n",
    "            \n",
    "    if del_clips:\n",
    "        for p in glob.glob(os.path.join(dest_dir, '*.MP4')):\n",
    "            os.remove(p)\n",
    "            \n",
    "    #prepare data loaders\n",
    "    if dataloaders:\n",
    "        print(f'net.input_mean: {net.input_mean}, net.input_std: {net.input_std}')\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "                    TSNDataSet(root_path, video_folders_filepath, num_segments=num_segments,\n",
    "                               new_length=1 if modality == \"RGB\" else 5,\n",
    "                               modality=modality,\n",
    "                               image_tmpl=prefix,\n",
    "                               test_mode=True,\n",
    "                               random_shift = False, #use consistent spacing between segments (frames)\n",
    "                               transform=torchvision.transforms.Compose([\n",
    "                                   cropping,\n",
    "                                   Stack(roll=(this_arch in ['BNInception', 'InceptionV3'])),\n",
    "                                   ToTorchFormatTensor(div=(this_arch not in ['BNInception', 'InceptionV3'])),\n",
    "                                   GroupNormalize([0.485, 0.456, 0.406], [0.485, 0.456, 0.406]),\n",
    "                               ]), dense_sample=dense_sample, twice_sample=twice_sample),\n",
    "                    batch_size=batch_size, shuffle=False,\n",
    "                    num_workers=num_workers, pin_memory=True,\n",
    "            )\n",
    "    else:\n",
    "        data_loader = None\n",
    "        \n",
    "    return {'data_loader': data_loader, 'videofolder':video_folders_filepath, 'fps':fps, 'frame_count':frame_count, 'width': width, 'height':height}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User1\\Desktop\\projects\\ITE_APAMS\\ite_dataset\\tmp\\A_1.MP4\n",
      "fps: 29.97002997002997, frame count: 1332, clip duration: 2, filename: A_1.MP4\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:11<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "net.input_mean: [0.485, 0.456, 0.406], net.input_std: [0.485, 0.456, 0.406]\n",
      "=> Using dense sample for the dataset...\n",
      "video number:22\n",
      "C:\\Users\\User1\\Desktop\\projects\\ITE_APAMS\\ite_dataset\\tmp\\A_2.MP4\n",
      "fps: 29.97002997002997, frame count: 2979, clip duration: 2, filename: A_2.MP4\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "net.input_mean: [0.485, 0.456, 0.406], net.input_std: [0.485, 0.456, 0.406]\n",
      "=> Using dense sample for the dataset...\n",
      "video number:50\n",
      "C:\\Users\\User1\\Desktop\\projects\\ITE_APAMS\\ite_dataset\\tmp\\A_3.MP4\n",
      "fps: 29.97002997002997, frame count: 1382, clip duration: 2, filename: A_3.MP4\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:17<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "net.input_mean: [0.485, 0.456, 0.406], net.input_std: [0.485, 0.456, 0.406]\n",
      "=> Using dense sample for the dataset...\n",
      "video number:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "video_dict = dict()\n",
    "for video_path in video_paths:\n",
    "    # if you have previously run this code and have the converted clips and frames in tmp_dir, then you can set preprocess=False\n",
    "    video_dict[video_path] = prepare_video(video_path, preprocess = True, dataloaders = True, del_clips=False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User1\\anaconda3\\envs\\ptcpu\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "net = torch.nn.DataParallel(net.to(dev))\n",
    "net.eval()\n",
    "for video_path in video_paths:\n",
    "    data_loader = video_dict[video_path]['data_loader']\n",
    "    data_gen = enumerate(data_loader)\n",
    "    this_rst_list = []\n",
    "    label_list = []\n",
    "    for i, (data, label) in data_gen:\n",
    "        rst = eval_video((i, data, label), net, this_test_segments, modality)\n",
    "\n",
    "        for l, r in zip(label, rst[1]): #unpack batch to individual samples\n",
    "            #save to lists\n",
    "            this_rst_list.append(r) \n",
    "            label_list.append(l) \n",
    "            \n",
    "    video_dict[video_path]['preds']= this_rst_list\n",
    "    video_dict[video_path]['labels']= label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save using pickle.....have to stop this to do object placement\n",
    "import pickle\n",
    "Path(output_path).mkdir(exist_ok=True)\n",
    "file_to_write = open( os.path.join(output_path, 'prediction_results'), \"wb\")\n",
    "pickle.dump(video_dict, file_to_write)\n",
    "\n",
    "file_to_write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading video_dict and all its predictions so as to not go through predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### variables required?\n",
    "cwd = \n",
    "output_path =  os.path.join(cwd, f'{dt}_{dataset_version}_nseg{num_segments}_ITE_VIDEO_results')\n",
    "\n",
    "##### please load categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "file_to_read = open(os.path.join(output_path, 'prediction_results'), \"rb\")\n",
    "\n",
    "video_dict = pickle.load(file_to_read)\n",
    "\n",
    "file_to_read.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read label map:\n",
    "with open(os.path.join(root_data_path, dataset_version, 'actions_label_map.txt'), 'r') as file:\n",
    "    categories = file.readlines()\n",
    "    categories = [c.strip().replace(' ', '_').replace('\"', '').replace('(', '').replace(')', '').replace(\"'\", '') for c in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['connect_alligator_clip',\n",
       " 'connect_atx_cable',\n",
       " 'connect_display_cable',\n",
       " 'connect_hdd_data_cable',\n",
       " 'connect_hdd_power_cable',\n",
       " 'connect_odd_data_cable',\n",
       " 'connect_odd_power_cable',\n",
       " 'disconnect_atx_cable',\n",
       " 'disconnect_display_cable',\n",
       " 'disconnect_hdd_data_cable',\n",
       " 'disconnect_hdd_power_cable',\n",
       " 'disconnect_odd_data_cable',\n",
       " 'disconnect_odd_power_cable',\n",
       " 'enter_bios_setup_mode',\n",
       " 'insert_hdd',\n",
       " 'insert_odd',\n",
       " 'insert_ram',\n",
       " 'insert_vga',\n",
       " 'login_screen',\n",
       " 'no_action',\n",
       " 'place_anti_static_mat',\n",
       " 'put_back_pc_casing',\n",
       " 'remove_hdd',\n",
       " 'remove_odd',\n",
       " 'remove_pc_casing',\n",
       " 'remove_ram',\n",
       " 'remove_vga',\n",
       " 'switch_off_power',\n",
       " 'switch_off_power_source',\n",
       " 'turn_on_pc',\n",
       " 'unplug_power_cable',\n",
       " 'verify_boot_sequence',\n",
       " 'wear_wrist_wrap']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_preds_from_csv(csv_path):\n",
    "    preds = list()\n",
    "    with open(csv_path) as file:\n",
    "        for line in file.readlines()[1:]:\n",
    "            pred = line.strip().split(',')[1:]\n",
    "#             pred = [float(i) for i in str_pred.split(',')]\n",
    "            preds.append(pred)\n",
    "    return preds\n",
    "\n",
    "def process_preds(preds, softmax_thresh=False, suppress_to = None):\n",
    "    pred_idxs = []\n",
    "    for pred in preds:\n",
    "        if softmax_thresh:\n",
    "            if max(pred)<softmax_thresh:\n",
    "                pred_idxs.append(suppress_to)\n",
    "            else:\n",
    "                pred_idxs.append(np.argmax(pred))\n",
    "    return pred_idxs\n",
    "\n",
    "def get_clips_paths(video_folders_filepath):\n",
    "    #get video clip paths from videofolder.txt\n",
    "    clip_paths = list()\n",
    "    with open(video_folders_filepath, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            clip_path = line.split(',')[0]+'.MP4'\n",
    "            clip_paths.append(clip_path)\n",
    "    return clip_paths\n",
    "\n",
    "def get_clips_lengths(video_folders_filepath):\n",
    "    #get video clip paths from videofolder.txt\n",
    "    clip_lengths = list()\n",
    "    with open(video_folders_filepath, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            clip_num_frames = int(line.split(',')[1])\n",
    "            clip_lengths.append(clip_num_frames)\n",
    "    return clip_lengths\n",
    "\n",
    "def save_preds_to_csv(video_path):\n",
    "    file_name = os.path.basename(video_path)\n",
    "    video_folders_filepath = video_dict[video_path]['videofolder']\n",
    "#     print(video_folders_filepath)\n",
    "    preds = video_dict[video_path]['preds']\n",
    "    labels = video_dict[video_path]['labels']\n",
    "        \n",
    "    #get video clip paths from videofolder.txt\n",
    "    clip_lengths = get_clips_lengths(video_folders_filepath)\n",
    "    print('number of preds: ', len(preds), 'number of clips: ',len(clip_lengths))\n",
    "    assert len(preds)==len(clip_lengths)\n",
    "    \n",
    "    # write results to csv file\n",
    "    csv_filepath = os.path.join(output_path, 'pred_'+file_name+'.csv')\n",
    "    csv_file = open(csv_filepath, 'w+')\n",
    "    cats_string = ','.join(categories)\n",
    "    csv_file.write(f'frame_pos,{cats_string}\\n')\n",
    "    i = 1\n",
    "    for raw_pred, label, clip_length in zip(preds, labels, clip_lengths):\n",
    "        #used to open clip to find number of frames\n",
    "        # now will just use value from videofolder.txt file to find that number\n",
    "        #get video properties\n",
    "        fps, frame_count, width, height = get_video_properties(video_path)\n",
    "        if clip_length > fps*CLIP_DURATION:\n",
    "            clip_length = fps*CLIP_DURATION #to avoid this problem: https://video.stackexchange.com/questions/23373/ffmpeg-not-creating-exact-duration-clip\n",
    "            \n",
    "        for j in range(int(clip_length)):\n",
    "            pred_str = ','.join([str(i) for i in raw_pred])\n",
    "            csv_file.write(f'{i},{pred_str}\\n')\n",
    "            i+= 1\n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write predictions to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of preds:  1049 number of clips:  1049\n",
      "number of preds:  933 number of clips:  933\n"
     ]
    }
   ],
   "source": [
    "for video_path in video_paths:\n",
    "    save_preds_to_csv(video_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process predictions \n",
    "Split by section using time, then suppress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF_THRES = 0.4 # previously 0.5 lead to worse scores than no confidence threshold\n",
    "USE_CONF_THRES = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for video_path in video_paths:\n",
    "    #read predictions from csv:\n",
    "    file_name = os.path.basename(video_path)\n",
    "    csv_filepath = os.path.join(output_path, 'pred_'+ file_name +'.csv')\n",
    "    preds = get_preds_from_csv(csv_filepath)    \n",
    "\n",
    "    #get video properties\n",
    "    fps, frame_count, width, height = get_video_properties(video_path)\n",
    "    \n",
    "    #process predictions\n",
    "    processed_preds = list()\n",
    "    predicted_actions = list()\n",
    "    pred_act_sect = list()\n",
    "    per_frame_sections = list()\n",
    "    processed_preds_unmasked = list()\n",
    "    \n",
    "    for idx, pred in enumerate(preds):\n",
    "        pred = [float(p) for p in pred]\n",
    "        #current minute into the video\n",
    "        current_minute = idx/fps/60\n",
    "        \n",
    "      \n",
    "        if USE_CONF_THRES:\n",
    "            # for actions (suppressed or not), check whether it meets a confidence criteria \n",
    "            if np.max(masked_preds) > CONF_THRES:\n",
    "                predicted_action = categories[np.argmax(pred)]      \n",
    "            else:\n",
    "                predicted_action = 'no_action'\n",
    "        else:\n",
    "            #get predicted action --- ORIGINAL, 22/6/2021\n",
    "            predicted_action = categories[np.argmax(pred)]\n",
    "            \n",
    "            \n",
    "            \n",
    "        predicted_actions.append(predicted_action)\n",
    "        \n",
    "    video_dict[video_path]['predicted_actions'] = predicted_actions\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write processed predictions to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62925\n",
      "55980\n"
     ]
    }
   ],
   "source": [
    "for video_path in video_paths:\n",
    "    #read predictions from csv:\n",
    "    file_name = os.path.basename(video_path)\n",
    "    csv_filepath = os.path.join(output_path, 'processed_pred_'+file_name+'.csv')\n",
    "    preds = video_dict[video_path]['predicted_actions']\n",
    "    print(len(preds))\n",
    "    with open(csv_filepath, 'w+') as file:\n",
    "        file.write(f'frame_pos,pred\\n')\n",
    "        for idx, pred in enumerate(preds):\n",
    "            file.write(f'{idx+1},{pred}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write predictions to video\n",
    "### warning: will take long time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing chanmunhong_01.MP4\n",
      "62925 1049\n",
      "62925 62925\n",
      "writing to: C:\\Users\\User1\\Desktop\\projects\\ITE_APAMS\\action_recoginition\\202108261801_pc_101_output\\pred_chanmunhong_01.MP4\n"
     ]
    }
   ],
   "source": [
    "#TODO: read preds from processed_preds csv file \n",
    "# def write_preds_to_video(video_path):\n",
    "for video_path in video_paths[0:1]: #video_paths[14:19] - TO SELECT A FEW\n",
    "    \n",
    "    file_name = os.path.basename(video_path)\n",
    "    print(f'processing {file_name}')\n",
    "    video_folders_filepath = video_dict[video_path]['videofolder']\n",
    "    \n",
    "    #get preds\n",
    "    preds = video_dict[video_path]['predicted_actions']\n",
    "\n",
    "    #get video clip paths from videofolder.txt\n",
    "    clip_paths = get_clips_paths(video_folders_filepath)\n",
    "    print(len(preds), len(clip_paths))\n",
    "    \n",
    "    fps, frame_count, width, height = get_video_properties(video_path)\n",
    "    print(len(preds),frame_count)\n",
    "    label_height = 60\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    \n",
    "    output_video_filepath = os.path.join(output_path, 'pred_'+file_name)\n",
    "    out = cv2.VideoWriter(output_video_filepath ,fourcc, fps, (width, height+label_height))\n",
    "    print(f'writing to: {output_video_filepath}')\n",
    "\n",
    "    i=0\n",
    "    for clip_path in clip_paths:        \n",
    "        \n",
    "        #open clip video\n",
    "        current_clip_frame_count = 0\n",
    "        cap = cv2.VideoCapture(clip_path) \n",
    "        while True:\n",
    "            _, img = cap.read()  \n",
    "\n",
    "            if not _:\n",
    "#                 print(\"No Image\")\n",
    "                cap.release()\n",
    "                break\n",
    "            elif current_clip_frame_count >= CLIP_DURATION*fps:\n",
    "                cap.release()\n",
    "                break\n",
    "            elif i >= len(preds):\n",
    "                print(f'pred limit reached. i={i}, clip_path = {clip_path}')\n",
    "                cap.release()\n",
    "                break\n",
    "            pred = preds[i]\n",
    "\n",
    "            \n",
    "#             print(current_section)\n",
    "#             if i%100==0:\n",
    "#                 print(pred)\n",
    "\n",
    "            label_area = np.zeros([label_height, width, 3]).astype('uint8') + 255\n",
    "    \n",
    "#             print(pred)\n",
    "\n",
    "            cv2.putText(label_area, \n",
    "                        f'Prediction: {pred}.  ',# ({max(pred):.6f}) Label: {labels[i]}',\n",
    "                        (5, int(label_height-20)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.7, \n",
    "                        (0, 0, 0), \n",
    "                        2)\n",
    "            img = np.concatenate((img, label_area), axis=0)\n",
    "            \n",
    "            out.write(img)\n",
    "            i+= 1\n",
    "            current_clip_frame_count += 1\n",
    "    out.release()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score predictions\n",
    "## Only possible for annotated videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chanmunhong_01.MP4\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\User1\\\\Desktop\\\\projects\\\\ITE_APAMS\\\\ite_dataset\\\\videos\\\\UAT_Stitched_Test_Cases\\\\chanmunhong_01.MP4.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-b5509ca065f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# read GT and convert to per-frame labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mgt_csv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo_path\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mgt_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt_csv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#remove no_action rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mgt_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgt_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgt_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'action'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m'no_action'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ptcpu\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ptcpu\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ptcpu\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ptcpu\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ptcpu\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ptcpu\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ptcpu\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ptcpu\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    702\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\User1\\\\Desktop\\\\projects\\\\ITE_APAMS\\\\ite_dataset\\\\videos\\\\UAT_Stitched_Test_Cases\\\\chanmunhong_01.MP4.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "iou_means = list()\n",
    "iou_per_class_all_videos_df = pd.DataFrame(columns=categories)\n",
    "\n",
    "for video_path in video_paths:\n",
    "    file_name = os.path.basename(video_path)\n",
    "    print(file_name)\n",
    "    \n",
    "    # read GT and convert to per-frame labels\n",
    "    gt_csv = video_path +'.csv'\n",
    "    gt_labels = pd.read_csv(gt_csv)\n",
    "    #remove no_action rows\n",
    "    gt_labels = gt_labels[gt_labels['action']!='no_action']\n",
    "    gt_labels.sort_values('z_start', inplace=True)\n",
    "    #get frame count and fps of video\n",
    "    frame_count = video_dict[video_path]['frame_count']\n",
    "    fps = video_dict[video_path]['fps']\n",
    "#     base_data = np.zeros((frame_count, len(categories)))\n",
    "    gt_labels_onehot = pd.DataFrame(0, index=np.arange(frame_count), columns=categories)\n",
    "    gt_labels_onehot.no_action = 1\n",
    "    for index, row in gt_labels.iterrows():\n",
    "        action, z_start, z_end = row\n",
    "        \n",
    "        #ignore action if it isn't in actions_label_map.txt\n",
    "        if action not in categories:\n",
    "            continue\n",
    "#         print(action, z_start, z_end)\n",
    "        frame_pos_start = int(z_start*fps)\n",
    "        frame_pos_end = int(z_end*fps)\n",
    "#         print(frame_pos_start, frame_pos_end)\n",
    "        gt_labels_onehot[action][frame_pos_start:frame_pos_end]=1\n",
    "        gt_labels_onehot.no_action[frame_pos_start:frame_pos_end]=0\n",
    "        \n",
    "    #read predictions file\n",
    "    output_csv_filepath = os.path.join(output_path, 'processed_pred_unmasked_'+ file_name + '.csv')\n",
    "    preds_per_frame = pd.read_csv(output_csv_filepath)\n",
    "    print(len(preds_per_frame), len(gt_labels_onehot))\n",
    "    \n",
    "    #convert to one-hot labels\n",
    "    preds_onehot = pd.DataFrame(0, index=np.arange(frame_count), columns=categories)\n",
    "    for index, row in preds_per_frame.iterrows():\n",
    "        frame_pos, action = row\n",
    "#         print(frame_pos, action)\n",
    "        preds_onehot[action][frame_pos-1] = 1\n",
    "    \n",
    "    intersection_per_class = (gt_labels_onehot*preds_onehot).sum()\n",
    "    union_per_class = (gt_labels_onehot|preds_onehot).sum()\n",
    "#     union_per_class = gt_labels_onehot.sum()+preds_onehot.sum()\n",
    "    iou_per_class = intersection_per_class/union_per_class\n",
    "    mean_iou = iou_per_class.mean()\n",
    "#     print(f'intersection: {intersection}, union: {union}')\n",
    "    iou_means.append(mean_iou)\n",
    "    iou_per_class_all_videos_df=iou_per_class_all_videos_df.append(iou_per_class, ignore_index=True)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_per_class_all_videos_df.to_csv('iou_per_class_all_videos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('iou mean per video:')\n",
    "iou_per_class_all_videos_df.mean(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('iou mean per class:')\n",
    "iou_per_class_all_videos_df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model score:')\n",
    "iou_per_class_all_videos_df.mean(axis=1, skipna=True).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model output analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "maxes = []\n",
    "for video_path in video_paths:\n",
    "#     print(video_dict[video_path])\n",
    "    file_name = os.path.basename(video_path)\n",
    "    preds = video_dict[video_path]['preds']\n",
    "    for pred in preds:\n",
    "        maxes.append(max(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(maxes, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(maxes)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
